{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of WordNet: (2-3 sentences)\n",
    "WordNet is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms called synsets.Using lexical relations and conceptual-semantic synsets are linked. The most used relation in WordNet is the similarity of words.This results in a network of meaningful concepts and related words that can be navigated by a computer, kind of like a thesaurus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('state.n.04'),\n",
       " Synset('country.n.02'),\n",
       " Synset('nation.n.02'),\n",
       " Synset('country.n.04'),\n",
       " Synset('area.n.01')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn \n",
    "wn.synsets('country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('nation.n.02')\n",
      "\n",
      "Synset defintion :  the people who live in a nation or country\n",
      "\n",
      "Synset usage examples :  [\"a statement that sums up the nation's mood\", 'the news was announced to the nation', 'the whole country worshipped him']\n",
      "\n",
      "Synset lemmas :  [Lemma('nation.n.02.nation'), Lemma('nation.n.02.land'), Lemma('nation.n.02.country')]\n"
     ]
    }
   ],
   "source": [
    "#noun_synset = [x for x in wn.synsets('country')]\n",
    "#print(noun_synset[2].name().split(\".\")[0])\n",
    "syn = wn.synsets('country')[2]\n",
    "print(syn)\n",
    "print (\"\\nSynset defintion : \", syn.definition())\n",
    "print (\"\\nSynset usage examples : \", syn.examples())\n",
    "print(\"\\nSynset lemmas : \", syn.lemmas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Couple sentences on how Word Net is organized for nouns: \n",
    "Nouns are grouped into sets of cognitive synonyms called synsets, every one showing a distinct concept. All noun hierarchies go up to the root node of a tree, the entity. From common nouns, cuntires, geographic enitites and specific persons, wordnet distinguishes between those. Very IS-A relationships. Utilizing hyponymy relations; if a tiger is a type of cat and a cat is a type of animal then a tiger is an animal. Dr. Richard C. Benson is an instance of a president. Instances are leaf nodes in their hierarchies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset hypernyms :  [Synset('people.n.01')]\n",
      "Synset hyponyms :  [Synset('british.n.01'), Synset('dutch.n.01'), Synset('english.n.02'), Synset('french.n.02'), Synset('irish.n.01'), Synset('spanish.n.02'), Synset('swiss.n.01')]\n",
      "Synset meronyms :  []\n",
      "Synset holonyms :  []\n",
      "Synset antonyms :  []\n"
     ]
    }
   ],
   "source": [
    "print(\"Synset hypernyms : \",syn.hypernyms())\n",
    "print(\"Synset hyponyms : \",syn.hyponyms())\n",
    "print(\"Synset meronyms : \", syn.part_meronyms())\n",
    "print(\"Synset holonyms : \",syn.member_holonyms())\n",
    "print(\"Synset antonyms : \", syn.lemmas()[0].antonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verb synsets :  [Synset('expression.n.01'), Synset('look.n.02'), Synset('look.n.03'), Synset('spirit.n.02'), Synset('look.v.01'), Synset('look.v.02'), Synset('look.v.03'), Synset('search.v.02'), Synset('front.v.01'), Synset('attend.v.02'), Synset('look.v.07'), Synset('expect.v.03'), Synset('look.v.09'), Synset('count.v.08')]\n",
      "Verb synset :  Synset('expression.n.01')\n",
      "Verb defintion :  the feelings expressed on a person's face\n",
      "Verb usage examples :  ['a sad expression', 'a look of triumph', 'an angry face']\n",
      "Vern lemmas :  [Lemma('expression.n.01.expression'), Lemma('expression.n.01.look'), Lemma('expression.n.01.aspect'), Lemma('expression.n.01.facial_expression'), Lemma('expression.n.01.face')]\n"
     ]
    }
   ],
   "source": [
    "synset_verb = wn.synsets('look')\n",
    "print(\"Verb synsets : \", synset_verb)\n",
    "syn_verb = wn.synsets('look')[0]\n",
    "print(\"Verb synset : \", syn_verb)\n",
    "print(\"Verb defintion : \", syn_verb.definition())\n",
    "print (\"Verb usage examples : \", syn_verb.examples())\n",
    "print(\"Verb lemmas : \", syn_verb.lemmas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Couple sentences on how Word Net is organized for verbs: \n",
    "Verbs are also grouped into sets of cognitive synonyms called synsets, every one showing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations. Verb synsets are arranged into hierarchies, verbs towards the bottom of the trees express increasingly specific manners characterizing an event, move, run, sprint. The specific manner expressed depends on the semantic field; Verbs can be elaborated by different dimensions. Speed, volume, intensity of emtion can all be dimensions in which a verb can be elaborated. Verbs describing events that necessarily and unidirectionally entail one another are linked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(wn.morphy(syn_verb.name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset name 1 :  run.n.01\n",
      "Synset name 2 :  move.n.01\n",
      "Synset 1 & 2 similarity :  0.6\n"
     ]
    }
   ],
   "source": [
    "syn1 = wn.synsets('run')[0]\n",
    "syn2 = wn.synsets('move')[0]\n",
    "print (\"Synset name 1 : \", syn1.name())\n",
    "print (\"Synset name 2 : \", syn2.name())\n",
    "print(\"Synset 1 & 2 similarity : \", syn1.wup_similarity(syn2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: synsets move and run are 60% percent similar. This also means that they share some common hypernyms. I thought run and move close but intially predicted maybe a 40% similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About SentiWordNet (functionality, use):\n",
    "SentiWordNet is an opinion lexicon derived from the WordNet database where each term is associated with numerical scores indicating positive and negative sentiment information. It is important to understand the sentiment behind a word, being able to determine whether an opinionated owrd has a postive of negative connocation. This is useful for computers to understand how a word is percieved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SentiSynset('plant.n.01'), SentiSynset('plant.n.02'), SentiSynset('plant.n.03'), SentiSynset('plant.n.04'), SentiSynset('plant.v.01'), SentiSynset('implant.v.01'), SentiSynset('establish.v.02'), SentiSynset('plant.v.04'), SentiSynset('plant.v.05'), SentiSynset('plant.v.06')]\n",
      "<plant.n.01: PosScore=0.0 NegScore=0.0> 0.0\n",
      "<plant.n.02: PosScore=0.0 NegScore=0.25> 0.0\n",
      "<plant.n.03: PosScore=0.0 NegScore=0.0> 0.0\n",
      "<plant.n.04: PosScore=0.0 NegScore=0.0> 0.0\n",
      "<plant.v.01: PosScore=0.0 NegScore=0.0> 0.0\n",
      "<implant.v.01: PosScore=0.0 NegScore=0.0> 0.0\n",
      "<establish.v.02: PosScore=0.0 NegScore=0.0> 0.0\n",
      "<plant.v.04: PosScore=0.0 NegScore=0.0> 0.0\n",
      "<plant.v.05: PosScore=0.0 NegScore=0.0> 0.0\n",
      "<plant.v.06: PosScore=0.125 NegScore=0.0> 0.125\n",
      "[SentiSynset('iodine.n.01'), SentiSynset('one.n.01'), SentiSynset('i.n.03'), SentiSynset('one.s.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('thymine.n.01'), SentiSynset('deoxythymidine_monophosphate.n.01'), SentiSynset('metric_ton.n.01'), SentiSynset('t.n.04'), SentiSynset('triiodothyronine.n.01'), SentiSynset('thyroxine.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[]\n",
      "[SentiSynset('tungsten.n.01'), SentiSynset('west.n.02'), SentiSynset('watt.n.01'), SentiSynset('w.n.04')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('angstrom.n.01'), SentiSynset('vitamin_a.n.01'), SentiSynset('deoxyadenosine_monophosphate.n.01'), SentiSynset('adenine.n.01'), SentiSynset('ampere.n.02'), SentiSynset('a.n.06'), SentiSynset('a.n.07')]\n",
      "[0.0]\n",
      "[0.0, 0.1]\n",
      "[0.0, 0.1, 0.0]\n",
      "[0.0, 0.1, 0.0, 0.0]\n",
      "[0.0, 0.1, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.1, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('second.n.01'), SentiSynset('sulfur.n.01'), SentiSynset('south.n.03'), SentiSynset('mho.n.01'), SentiSynset('s.n.05'), SentiSynset('randomness.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[]\n",
      "[SentiSynset('thymine.n.01'), SentiSynset('deoxythymidine_monophosphate.n.01'), SentiSynset('metric_ton.n.01'), SentiSynset('t.n.04'), SentiSynset('triiodothyronine.n.01'), SentiSynset('thyroxine.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('hydrogen.n.01'), SentiSynset('henry.n.01'), SentiSynset('planck's_constant.n.01'), SentiSynset('h.n.04'), SentiSynset('heat_content.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('vitamin_e.n.01'), SentiSynset('einsteinium.n.01'), SentiSynset('east.n.01'), SentiSynset('e.n.04'), SentiSynset('e.n.05')]\n",
      "[0.375]\n",
      "[0.375, 0.0]\n",
      "[0.375, 0.0, 0.0]\n",
      "[0.375, 0.0, 0.0, 0.0]\n",
      "[0.375, 0.0, 0.0, 0.0, 0.0]\n",
      "[]\n",
      "[SentiSynset('bacillus.n.01'), SentiSynset('b-complex_vitamin.n.01'), SentiSynset('boron.n.01'), SentiSynset('bel.n.01'), SentiSynset('barn.n.02'), SentiSynset('b.n.06'), SentiSynset('b.n.07')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('vitamin_e.n.01'), SentiSynset('einsteinium.n.01'), SentiSynset('east.n.01'), SentiSynset('e.n.04'), SentiSynset('e.n.05')]\n",
      "[0.375]\n",
      "[0.375, 0.0]\n",
      "[0.375, 0.0, 0.0]\n",
      "[0.375, 0.0, 0.0, 0.0]\n",
      "[0.375, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('second.n.01'), SentiSynset('sulfur.n.01'), SentiSynset('south.n.03'), SentiSynset('mho.n.01'), SentiSynset('s.n.05'), SentiSynset('randomness.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('thymine.n.01'), SentiSynset('deoxythymidine_monophosphate.n.01'), SentiSynset('metric_ton.n.01'), SentiSynset('t.n.04'), SentiSynset('triiodothyronine.n.01'), SentiSynset('thyroxine.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[]\n",
      "[SentiSynset('oxygen.n.01'), SentiSynset('o.n.02'), SentiSynset('o.n.03')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[SentiSynset('degree_fahrenheit.n.01'), SentiSynset('fluorine.n.01'), SentiSynset('farad.n.01'), SentiSynset('f.n.04')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[]\n",
      "[SentiSynset('thymine.n.01'), SentiSynset('deoxythymidine_monophosphate.n.01'), SentiSynset('metric_ton.n.01'), SentiSynset('t.n.04'), SentiSynset('triiodothyronine.n.01'), SentiSynset('thyroxine.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('iodine.n.01'), SentiSynset('one.n.01'), SentiSynset('i.n.03'), SentiSynset('one.s.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('meter.n.01'), SentiSynset('molarity.n.01'), SentiSynset('thousand.n.01'), SentiSynset('megabyte.n.01'), SentiSynset('megabyte.n.02'), SentiSynset('m.n.06'), SentiSynset('thousand.s.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('vitamin_e.n.01'), SentiSynset('einsteinium.n.01'), SentiSynset('east.n.01'), SentiSynset('e.n.04'), SentiSynset('e.n.05')]\n",
      "[0.375]\n",
      "[0.375, 0.0]\n",
      "[0.375, 0.0, 0.0]\n",
      "[0.375, 0.0, 0.0, 0.0]\n",
      "[0.375, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('second.n.01'), SentiSynset('sulfur.n.01'), SentiSynset('south.n.03'), SentiSynset('mho.n.01'), SentiSynset('s.n.05'), SentiSynset('randomness.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[]\n",
      "[]\n",
      "[SentiSynset('iodine.n.01'), SentiSynset('one.n.01'), SentiSynset('i.n.03'), SentiSynset('one.s.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('thymine.n.01'), SentiSynset('deoxythymidine_monophosphate.n.01'), SentiSynset('metric_ton.n.01'), SentiSynset('t.n.04'), SentiSynset('triiodothyronine.n.01'), SentiSynset('thyroxine.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[]\n",
      "[SentiSynset('tungsten.n.01'), SentiSynset('west.n.02'), SentiSynset('watt.n.01'), SentiSynset('w.n.04')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('angstrom.n.01'), SentiSynset('vitamin_a.n.01'), SentiSynset('deoxyadenosine_monophosphate.n.01'), SentiSynset('adenine.n.01'), SentiSynset('ampere.n.02'), SentiSynset('a.n.06'), SentiSynset('a.n.07')]\n",
      "[0.0]\n",
      "[0.0, 0.1]\n",
      "[0.0, 0.1, 0.0]\n",
      "[0.0, 0.1, 0.0, 0.0]\n",
      "[0.0, 0.1, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.1, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('second.n.01'), SentiSynset('sulfur.n.01'), SentiSynset('south.n.03'), SentiSynset('mho.n.01'), SentiSynset('s.n.05'), SentiSynset('randomness.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[]\n",
      "[SentiSynset('thymine.n.01'), SentiSynset('deoxythymidine_monophosphate.n.01'), SentiSynset('metric_ton.n.01'), SentiSynset('t.n.04'), SentiSynset('triiodothyronine.n.01'), SentiSynset('thyroxine.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('hydrogen.n.01'), SentiSynset('henry.n.01'), SentiSynset('planck's_constant.n.01'), SentiSynset('h.n.04'), SentiSynset('heat_content.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('vitamin_e.n.01'), SentiSynset('einsteinium.n.01'), SentiSynset('east.n.01'), SentiSynset('e.n.04'), SentiSynset('e.n.05')]\n",
      "[0.375]\n",
      "[0.375, 0.0]\n",
      "[0.375, 0.0, 0.0]\n",
      "[0.375, 0.0, 0.0, 0.0]\n",
      "[0.375, 0.0, 0.0, 0.0, 0.0]\n",
      "[]\n",
      "[SentiSynset('tungsten.n.01'), SentiSynset('west.n.02'), SentiSynset('watt.n.01'), SentiSynset('w.n.04')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('oxygen.n.01'), SentiSynset('o.n.02'), SentiSynset('o.n.03')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[SentiSynset('roentgen.n.01'), SentiSynset('gas_constant.n.01'), SentiSynset('r.n.03'), SentiSynset('radius.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('second.n.01'), SentiSynset('sulfur.n.01'), SentiSynset('south.n.03'), SentiSynset('mho.n.01'), SentiSynset('s.n.05'), SentiSynset('randomness.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('thymine.n.01'), SentiSynset('deoxythymidine_monophosphate.n.01'), SentiSynset('metric_ton.n.01'), SentiSynset('t.n.04'), SentiSynset('triiodothyronine.n.01'), SentiSynset('thyroxine.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[]\n",
      "[SentiSynset('oxygen.n.01'), SentiSynset('o.n.02'), SentiSynset('o.n.03')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[SentiSynset('degree_fahrenheit.n.01'), SentiSynset('fluorine.n.01'), SentiSynset('farad.n.01'), SentiSynset('f.n.04')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[]\n",
      "[SentiSynset('thymine.n.01'), SentiSynset('deoxythymidine_monophosphate.n.01'), SentiSynset('metric_ton.n.01'), SentiSynset('t.n.04'), SentiSynset('triiodothyronine.n.01'), SentiSynset('thyroxine.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('iodine.n.01'), SentiSynset('one.n.01'), SentiSynset('i.n.03'), SentiSynset('one.s.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('meter.n.01'), SentiSynset('molarity.n.01'), SentiSynset('thousand.n.01'), SentiSynset('megabyte.n.01'), SentiSynset('megabyte.n.02'), SentiSynset('m.n.06'), SentiSynset('thousand.s.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('vitamin_e.n.01'), SentiSynset('einsteinium.n.01'), SentiSynset('east.n.01'), SentiSynset('e.n.04'), SentiSynset('e.n.05')]\n",
      "[0.375]\n",
      "[0.375, 0.0]\n",
      "[0.375, 0.0, 0.0]\n",
      "[0.375, 0.0, 0.0, 0.0]\n",
      "[0.375, 0.0, 0.0, 0.0, 0.0]\n",
      "[SentiSynset('second.n.01'), SentiSynset('sulfur.n.01'), SentiSynset('south.n.03'), SentiSynset('mho.n.01'), SentiSynset('s.n.05'), SentiSynset('randomness.n.01')]\n",
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\saige\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saige\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from operator import countOf\n",
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "nltk.download(\"sentiwordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "#for each plant synset in plants synset, output the polarity score \n",
    "p_score = 0.0\n",
    "plants = [ x for x in swn.senti_synsets(\"plant\")]\n",
    "print(plants)\n",
    "for i in plants:\n",
    "    scores = ( i.pos_score() / (i.neg_score()+1.0) )\n",
    "    print(i, scores)\n",
    "\n",
    "#for each word in raw text, output polarity \n",
    "raw_text = \"it was the best of times, it was the worst of times.\"\n",
    "for j in raw_text:\n",
    "    word = [x for x in swn.senti_synsets(j)]\n",
    "    print(word)\n",
    "    c = []\n",
    "    for i in word:\n",
    "        c.append((i.pos_score() / (i.neg_score()+1.0)))\n",
    "       # score = (i.pos_score() / (i.neg_score()+1.0))\n",
    "        print(c)\n",
    "        #print(i, score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: It is a lot different than regular synsets. \"It was the best of times, it was the worst of times\". Each word had widely different sentisynsets, which I did not expect. Polarity is interesting, where -1 refers to negative sentiment and +1 refers to positive sentiment. Getting computers to understand the sentiment of text is understanding the sentiment behind words. This is really helpful when it comes to natural language processing and how this word can effect the sentiment of a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocations - words that tend to go together, they are almost like cliches (crystal clear, sick and tired) When two of more words combine more often than expected by chance, and you cannot substitute a word and get the same meaning (wild rice, unruly rice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n",
      "152901 134 241\n",
      "('Fellow', '-') 7\n",
      "('Fellow', 'Citizens') 6\n",
      "('-', 'Citizens') 5\n",
      "Fellow citizens pmi :  28.407939555335354\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n",
    "from nltk.collocations import *\n",
    "import nltk\n",
    "count = 0\n",
    "wordX = 0\n",
    "wordY = 0\n",
    "colo = 0\n",
    "k = 'fellow'\n",
    "v = 'fellow'\n",
    "collos = [text4.collocations()]\n",
    "\n",
    "total_words = text4.tokens\n",
    "for i in total_words:\n",
    "    count +=1\n",
    "    if(i == 'fellow'):\n",
    "        wordX +=1\n",
    "    if(i == 'citizens'):\n",
    "        wordY +=1\n",
    "print(count, wordX, wordY)\n",
    "finder = BigramCollocationFinder.from_words(total_words[: ], window_size = 3)\n",
    "finder1 = BigramCollocationFinder.from_words(total_words[: ], window_size = 3)\n",
    "finder1.apply_freq_filter(2)\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "for k,v in finder.ngram_fd.items():\n",
    "  print(k,v)\n",
    "  colo +=1\n",
    "  if(colo == 3):\n",
    "    break\n",
    "wordXY = 6\n",
    "pmi = ((wordXY/count)/((wordX/count)*(wordY/count)))\n",
    "print(\"Fellow citizens pmi : \", pmi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My approach was to find the frequencies of each word in the text then create the probability equation using the total words in the text, the amount of times wordX occured, the amount of times wordY occured and the amount of times they occured together. In my case I chose \"Fellow citizens\". "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
